{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anumit-web/ML-Analytics-Portfolio-2024/blob/main/6.%20Sentiment%20Analysis/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Artificial Intelligence\n",
        "# Machine Learning\n",
        "# Portfolio Project\n",
        "# #6\n",
        "# Sentiment Analysis\n",
        "# Perform Sentiment Analysis on customer reviews or social media posts\n",
        "\n",
        "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n"
      ],
      "metadata": {
        "id": "LAElxz7e6xiT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Branding statement"
      ],
      "metadata": {
        "id": "-AqinKkKYcIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://i.ibb.co/zZswY34/Pink-hands-network-2.png"
      ],
      "metadata": {
        "id": "et0ThJcPYiXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('https://i.ibb.co/zZswY34/Pink-hands-network-2.png')"
      ],
      "metadata": {
        "id": "eejritJ1YnWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -"
      ],
      "metadata": {
        "id": "GRLJj5WkZYii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA, Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "P2GTILYG7D1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import libraries"
      ],
      "metadata": {
        "id": "vSS7v0tO2Nc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Hello, Sentiment Analysis')"
      ],
      "metadata": {
        "id": "bijVEivnAsug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "vsLbE4-Z-pdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Control group"
      ],
      "metadata": {
        "id": "zlPRSWa00y-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df = pd.read_csv(\"https://raw.githubusercontent.com/anumit-web/ML-Analytics-Portfolio-2024/refs/heads/main/6.%20Sentiment%20Analysis/dataset/sentiment_analysis.csv\",sep=\",\")"
      ],
      "metadata": {
        "id": "GqVUsHF_EUrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal analyze the result of AB testing for marketing campaign or website feature."
      ],
      "metadata": {
        "id": "re4F9rRwBRZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "o7enKsiz_UEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df.tail()"
      ],
      "metadata": {
        "id": "SGHOpPwkXjte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df.info()"
      ],
      "metadata": {
        "id": "S_h0_YgEXsVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df.describe()\n"
      ],
      "metadata": {
        "id": "N5WFB738XyUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "print column names"
      ],
      "metadata": {
        "id": "GUlKmkJKaoSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_data_df.columns)"
      ],
      "metadata": {
        "id": "L5hw6CkxZTo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all Column Header Labels as List\n",
        "for column_headers in  input_data_df.columns:\n",
        "    print(column_headers)"
      ],
      "metadata": {
        "id": "SNohuK30aZ-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## find list of all columns which have null values\n",
        "using SKIMPY"
      ],
      "metadata": {
        "id": "-6YgPJxE3ALE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the count of null values in each column\n",
        "null_counts = input_data_df.isnull().sum()\n",
        "print(null_counts)"
      ],
      "metadata": {
        "id": "4TQRUjgl9NSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import skimpy\n",
        "except:\n",
        "  !pip install skimpy\n",
        "  import skimpy"
      ],
      "metadata": {
        "id": "4YTP4QMQ-n0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install skimpy"
      ],
      "metadata": {
        "id": "JXCuQMzKcRv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimpy import skim"
      ],
      "metadata": {
        "id": "ihugGf-bcd-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skim(input_data_df)"
      ],
      "metadata": {
        "id": "Ol4qOryGckPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## find unique values by column names"
      ],
      "metadata": {
        "id": "Eh836kWO3jwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the number of unique values in both 'Name' and 'Age' columns\n",
        "unique_values = input_data_df.nunique()\n",
        "print(unique_values)"
      ],
      "metadata": {
        "id": "-uIq1pUW-fG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import summarytools\n",
        "except:\n",
        "  !pip install summarytools\n",
        "  import summarytools"
      ],
      "metadata": {
        "id": "WBNzRoXv_Q6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install summarytools"
      ],
      "metadata": {
        "id": "r29v3j-ndm_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from summarytools import dfSummary"
      ],
      "metadata": {
        "id": "QH1rhk3zdxt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfSummary(input_data_df)"
      ],
      "metadata": {
        "id": "O4BP8AQvd1hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "na0uFDyjW7gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print\n",
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "kw6A08RozjR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization ðŸ“ŠðŸ“ˆðŸ“‰"
      ],
      "metadata": {
        "id": "ZxkH60cC3ecY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## find number of sentiments in dataset"
      ],
      "metadata": {
        "id": "DEB1iajD3tRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pie_data_df = input_data_df.groupby('sentiment').count().reset_index()\n",
        "\n",
        "# print\n",
        "pie_data_df"
      ],
      "metadata": {
        "id": "rOtzFcx04cx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['sentiment', 'count']\n",
        "\n",
        "pie_data_df = pie_data_df.filter(['sentiment', 'Year'])\n",
        "\n",
        "#print\n",
        "pie_data_df\n",
        "\n",
        "columns = ['sentiment', 'count']\n",
        "\n",
        "pie_data_df"
      ],
      "metadata": {
        "id": "gT7eOItm_0lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['sentiment', 'count']\n",
        "\n",
        "pie_data_df.columns = columns\n",
        "\n",
        "# print\n",
        "pie_data_df.head()"
      ],
      "metadata": {
        "id": "zbR0pmHqClRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a pie chart\n",
        "plt.figure(figsize=(6, 8))\n",
        "plt.pie(pie_data_df['count'], labels=pie_data_df['sentiment'], autopct='%1.1f%%')\n",
        "plt.title('Sentiment/Vibe of post/tweet')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UN4gGf6t3sO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## find average number of letters or alphabets in a tweet categorized by sentiment type"
      ],
      "metadata": {
        "id": "eS6Ua_0KFq9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change column names"
      ],
      "metadata": {
        "id": "68LFfGIbXBqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fill mean average values in rows and columns"
      ],
      "metadata": {
        "id": "-IZO_j2kZRah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "\n",
        "# add a coulmns\n",
        "\n",
        "input_data_df[\"total_alphabets\"] = 0\n",
        "\n",
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "3C4_o5guHhbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df[\"total_alphabets\"] = input_data_df[\"text\"].apply(len)\n",
        "\n",
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "iUjPpmBOIAN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bar_chart_data_df = input_data_df.filter(['sentiment', 'total_alphabets'])\n",
        "\n",
        "# print\n",
        "bar_chart_data_df.head()"
      ],
      "metadata": {
        "id": "u78-e_k2IekU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bar_chart_data_df = bar_chart_data_df.groupby('sentiment')['total_alphabets'].mean().reset_index()\n",
        "\n",
        "# print\n",
        "bar_chart_data_df.head()"
      ],
      "metadata": {
        "id": "Nh-qvzBYsVrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['sentiment', 'average_alphabets']\n",
        "\n",
        "bar_chart_data_df.columns = columns\n",
        "\n",
        "# print\n",
        "bar_chart_data_df"
      ],
      "metadata": {
        "id": "lJCR0RE5thHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set()\n",
        "plt.figure(figsize=(8, 6))\n",
        "colors = ['#f46a9b', '#ede15b', '#87bc45']\n",
        "sns.barplot(x='sentiment', y='average_alphabets', data=bar_chart_data_df, palette=colors)\n",
        "plt.title('Average Number of Alphabets in Tweets by Sentiment')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WnOBvZxSvDDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Calculations"
      ],
      "metadata": {
        "id": "jd0vqbaVZiEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## strategy\n",
        "1. Lower case string\n",
        "2. Tokenization\n",
        "3. punctuation removal\n",
        "4. Stop Words\n",
        "5. Stemming\n",
        "6. Lemmatization\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vfrS4mypZi2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization"
      ],
      "metadata": {
        "id": "R-oLO-_9BfZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "zpBpqNYbCFlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_location = input_data_df.columns.get_loc('text')\n",
        "\n",
        "# Create a new column 'Country'\n",
        "input_data_df['text_processed'] = \"\"\n",
        "\n",
        "# Insert the 'Country' column after the 'Name' column\n",
        "input_data_df.insert(text_location + 1, 'text_processed', input_data_df.pop('text_processed'))\n",
        "\n",
        "text_processed_location = input_data_df.columns.get_loc('text_processed')\n",
        "\n",
        "# Create a new column 'Country'\n",
        "input_data_df['text_processed_2'] = \"\"\n",
        "\n",
        "# Insert the 'Country' column after the 'Name' column\n",
        "input_data_df.insert(text_processed_location + 1, 'text_processed_2', input_data_df.pop('text_processed_2'))\n",
        "\n",
        "text_processed_location_2 = input_data_df.columns.get_loc('text_processed_2')\n",
        "\n",
        "# Create a new column 'Country'\n",
        "input_data_df['text_processed_3'] = \"\"\n",
        "\n",
        "# Insert the 'Country' column after the 'Name' column\n",
        "input_data_df.insert(text_processed_location_2 + 1, 'text_processed_3', input_data_df.pop('text_processed_3'))\n",
        "\n",
        "\n",
        "# print\n",
        "\n",
        "input_data_df.head()\n",
        "\n",
        "# print\n",
        "\n",
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "C0ar_eP0DVEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zpFTrK1WPvXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Lower case string"
      ],
      "metadata": {
        "id": "cAZ5LcyMgXmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df['text_processed'] = input_data_df['text'].str.lower()\n",
        "\n",
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "BB8jsoD0IRlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. tokenize sentenses"
      ],
      "metadata": {
        "id": "z4rbIpfrhYDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "metadata": {
        "id": "d7HlNSriF-tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Tokenize the 'text' column and put the result in a new column 'tokens'\n",
        "input_data_df['text_processed'] = input_data_df['text_processed'].apply(word_tokenize)\n",
        "\n",
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "lFsttLD1GSzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## punctuation removal"
      ],
      "metadata": {
        "id": "AZAbNSOthSCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_data_df['text_processed_2'] = input_data_df['text_processed'].copy()\n",
        "\n",
        "input_data_df.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "lgRbG_EGDWAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df.loc[:, 'text_processed_3'] = input_data_df.loc[:, 'text_processed_2']\n",
        "\n",
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "bW9U0R5GlFRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "# input_data_df['text_processed_2'] = input_data_df['text_processed'].copy()\n",
        "\n",
        "def remove_punctuation(tokens):\n",
        "\n",
        "  tokens2 = []\n",
        "  for word in tokens:\n",
        "    #if (word in string.punctuation):\n",
        "      #tokens.remove(word)\n",
        "    if(word not in string.punctuation):\n",
        "      tokens2.append(word)\n",
        "\n",
        "  #return tokens\n",
        "  return tokens2\n",
        "  # return \"\"\n",
        "\n",
        "# input_data_df['text_processed_2'] = input_data_df['text_processed']\n",
        "input_data_df['text_processed_3'] = input_data_df['text_processed_3'].apply(remove_punctuation)\n",
        "\n",
        "input_data_df.head(5)\n",
        "\n",
        "# input_data_df['text', 'text_processed'].head()"
      ],
      "metadata": {
        "id": "AZjskqAfJFrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## stop words removal"
      ],
      "metadata": {
        "id": "hD4WKtjmuL1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "EFr3RpDpufj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def remove_stop_words(tokens):\n",
        "\n",
        "  tokens2 = []\n",
        "  for word in tokens:\n",
        "    #if (word in stopwords.words('english')):\n",
        "       #tokens.remove(word)\n",
        "    if ( word not in stopwords.words('english')):\n",
        "         tokens2.append(word)\n",
        "\n",
        "  #return tokens\n",
        "  return tokens2\n",
        "\n",
        "input_data_df['text_processed_3'] = input_data_df['text_processed_3'].apply(remove_stop_words)\n",
        "\n",
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "sDxqwB_quicS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. stemming"
      ],
      "metadata": {
        "id": "80M2B1Kjxu-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "metadata": {
        "id": "6SqPmHx6x05n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "porter_stemmer = PorterStemmer()\n",
        "snowball_stemmer = SnowballStemmer(\"english\") # use this algorithm as it is new version of porter\n",
        "\n",
        "def stemwords_in_sentence(tokens):\n",
        "  stemmed_words = []\n",
        "  for word in tokens:\n",
        "      stemmed_word = snowball_stemmer.stem(word)\n",
        "      stemmed_words.append(stemmed_word)\n",
        "\n",
        "\n",
        "  return stemmed_words\n",
        "\n",
        "input_data_df['text_processed_3'] = input_data_df['text_processed_3'].apply(stemwords_in_sentence)\n",
        "\n",
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "JB5TqOeozOHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. lemming"
      ],
      "metadata": {
        "id": "83Ik5U-1-e1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "expVZgIU-ko9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_in_sentence(tokens):\n",
        "  lemmatized_words = []\n",
        "  for word in tokens:\n",
        "      lemmatized_word =   lemmatizer.lemmatize(word)\n",
        "      lemmatized_words.append(lemmatized_word)\n",
        "\n",
        "\n",
        "  return lemmatized_words\n",
        "\n",
        "input_data_df['text_processed_3'] = input_data_df['text_processed_3'].apply(lemmatize_in_sentence)\n",
        "\n",
        "input_data_df.head()\n"
      ],
      "metadata": {
        "id": "7HVCYeMO-oDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Join tokens into string"
      ],
      "metadata": {
        "id": "7bMDT1HzWtQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input_data_df['text_processed_3'] ="
      ],
      "metadata": {
        "id": "MQTND5yRXpU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_processed_location_3 = input_data_df.columns.get_loc('text_processed_3')\n",
        "\n",
        "# Create a new column 'Country'\n",
        "input_data_df['text_processed_4'] = \"\"\n",
        "\n",
        "# Insert the 'Country' column after the 'Name' column\n",
        "input_data_df.insert(text_processed_location_3 + 1, 'text_processed_4', input_data_df.pop('text_processed_4'))\n",
        "\n"
      ],
      "metadata": {
        "id": "z1Hq-WVJZObq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df['text_processed_4'] = input_data_df['text_processed_3'].apply(lambda token: ' '.join(token))"
      ],
      "metadata": {
        "id": "5jLgZZ1XAdXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "xx28FDUpYfSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change column names"
      ],
      "metadata": {
        "id": "Tvc1t_iNZjXG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fill mean average values in rows and columns"
      ],
      "metadata": {
        "id": "dlI7AVmNOUJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process combined data from control group and test group"
      ],
      "metadata": {
        "id": "iVyBC2XdQiuR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Calculations"
      ],
      "metadata": {
        "id": "UcZlGRiCMT1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find sentiment of tweets and posts"
      ],
      "metadata": {
        "id": "rUjHz0QUTLqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VADER (Valence Aware Dictionary and sEntiment Reasoner)"
      ],
      "metadata": {
        "id": "kfVKWCcVT5mN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "negative, neutral, and positive scores\n",
        "\n",
        "compound score can range from -1 to 1."
      ],
      "metadata": {
        "id": "GRwSSjKaaKXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "daLN9xeyTKpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sia = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "71qirqBaV1EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sia.polarity_scores(\"Wow, NLTK is really powerful!\")"
      ],
      "metadata": {
        "id": "9gqJynpHUNky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sia.polarity_scores(\"I had a bad experience at the geocery store!\")"
      ],
      "metadata": {
        "id": "l--_EqsNaIdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sia.polarity_scores(\"I am going to office\")"
      ],
      "metadata": {
        "id": "iOrh718Ucbd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create get_sentiment function\n",
        "\n",
        "def get_sentiment(text):\n",
        "\n",
        "    scores = sia.polarity_scores(text)\n",
        "\n",
        "    if scores['compound'] > 0 :\n",
        "        new_sentiment = 1\n",
        "    if scores['compound'] == 0 :\n",
        "        new_sentiment = 0\n",
        "    if scores['compound'] < 0 :\n",
        "        new_sentiment = -1\n",
        "\n",
        "    return new_sentiment\n",
        "\n",
        "\n",
        "# apply get_sentiment function\n",
        "\n",
        "input_data_df['calculated_sentiment'] = input_data_df['text_processed_4'].apply(get_sentiment)\n",
        "\n",
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "Fs7POSe-aaR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by the 'Name' column and count the number of rows in each group\n",
        "result =  input_data_df.groupby('calculated_sentiment').size()\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "EsYPlXBohCT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_location = input_data_df.columns.get_loc('sentiment')\n",
        "\n",
        "# Create a new column 'Country'\n",
        "input_data_df['sentiment_to_number'] = 9999999\n",
        "\n",
        "# Insert the 'Country' column after the 'Name' column\n",
        "input_data_df.insert(sentiment_location + 1, 'sentiment_to_number', input_data_df.pop('sentiment_to_number'))\n",
        "\n",
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "BiyR_mFpi40t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_sentiment_to_number(sentiment):\n",
        "\n",
        "  sentiment_number = 66666666\n",
        "\n",
        "  if(sentiment == 'positive')\n",
        "    sentiment_number = 1\n",
        "  if(sentiment == 'neutral')\n",
        "    sentiment_number = 0\n",
        "  if(sentiment == 'negative')\n",
        "     sentiment_number = -1\n",
        "\n",
        "  return sentiment_number\n",
        "  # return \"\"\n",
        "\n",
        "# input_data_df['text_processed_2'] = input_data_df['text_processed']\n",
        "input_data_df['sentiment_to_number'] = input_data_df['sentiment'].apply(convert_sentiment_to_number)\n",
        "\n",
        "input_data_df.head(5)"
      ],
      "metadata": {
        "id": "6d1mY-5ojhPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CTR (Click-Through Rate)\n",
        "\n",
        "CTR = (Number of Clicks / Number of Impressions) x 100"
      ],
      "metadata": {
        "id": "8WS-2ZEvZj1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conversion Rate\n",
        "\n",
        "Conversion Rate = (Number of Conversions / Number of Visitors) x 100"
      ],
      "metadata": {
        "id": "PyRat1vNZkWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "add new columns\n",
        "normalized = value between 0 and 1\n",
        "percent = value between 0 and 100"
      ],
      "metadata": {
        "id": "TwTvrOgmdVlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data_df['CTR_Normalized'] = 0\n",
        "combined_data_df['CTR_Percent'] = 0\n",
        "combined_data_df['CR_Normalized'] = 0\n",
        "combined_data_df['CR_Percent'] = 0\n",
        "\n",
        "#print\n",
        "combined_data_df.head()"
      ],
      "metadata": {
        "id": "5tnj2RQpdZNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data_df['CTR_Normalized'] = (combined_data_df['Clicks'] /\n",
        "                      combined_data_df['Impressions'])\n",
        "\n",
        "combined_data_df['CTR_Percent'] = (combined_data_df['Clicks'] /\n",
        "                      combined_data_df['Impressions']) * 100\n",
        "\n",
        "# print\n",
        "combined_data_df.head()"
      ],
      "metadata": {
        "id": "FaiaLuaGfKdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data_df['CR_Normalized'] = (combined_data_df['Purchases'] /\n",
        "                      combined_data_df['Clicks'])\n",
        "\n",
        "combined_data_df['CR_Percent'] = (combined_data_df['Purchases'] /\n",
        "                      combined_data_df['Clicks']) * 100\n",
        "\n",
        "\n",
        "#print\n",
        "combined_data_df.head()"
      ],
      "metadata": {
        "id": "vFMAAvgvf6jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CTR\n",
        "\n",
        "temp_df1 = combined_data_df.groupby('Campaign Name')['CTR_Normalized'].mean()\n"
      ],
      "metadata": {
        "id": "MfPy_ezyztOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df2 = combined_data_df.groupby('Campaign Name')['CR_Normalized'].mean()"
      ],
      "metadata": {
        "id": "r9SIDO1X0BsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df3 = combined_data_df.groupby('Campaign Name')['CTR_Percent'].mean()"
      ],
      "metadata": {
        "id": "59hifgR91eou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df4 = combined_data_df.groupby('Campaign Name')['CR_Percent'].mean()"
      ],
      "metadata": {
        "id": "dGOKDMdA1oYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df5 = pd.merge(temp_df1, temp_df2, on='Campaign Name')\n",
        "\n",
        "#print\n",
        "temp_df5"
      ],
      "metadata": {
        "id": "D8dsC1Se1CkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df6 = pd.merge(temp_df3, temp_df4, on='Campaign Name')"
      ],
      "metadata": {
        "id": "K0bSUg1V2Epg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df7 = pd.merge(temp_df5, temp_df6, on='Campaign Name')\n",
        "\n",
        "# print\n",
        "temp_df7"
      ],
      "metadata": {
        "id": "ftelQiYj2LVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculations_df = temp_df7\n",
        "\n",
        "# print\n",
        "temp_df7"
      ],
      "metadata": {
        "id": "vGJ3edLt2sno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "seperator"
      ],
      "metadata": {
        "id": "gnTBZzuD3KbA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "seperator"
      ],
      "metadata": {
        "id": "Q3ZC4rWl3ORh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "bF-P0sW24ipO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CTR , Click through rate"
      ],
      "metadata": {
        "id": "dOJrb6dj5Iun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bar chart of CTR"
      ],
      "metadata": {
        "id": "G0kluhEVZk7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = sns.color_palette(['#06C', '#F4B678'])\n",
        "\n",
        "sns.barplot(data=calculations_df, x='Campaign Name',\n",
        "                    y='CTR_Percent', hue='Campaign Name', palette = colors, dodge=False)\n",
        "plt.title('Average Metrics of CTR')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0hxBXqqw5Y36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Box chart of CTR"
      ],
      "metadata": {
        "id": "iRPnlOoO4pJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = sns.color_palette(['#73C5C5', '#A30000'])\n",
        "\n",
        "sns.boxplot(x='Campaign Name', y='CTR_Normalized', data=combined_data_df,\n",
        "            hue='Campaign Name', dodge=False, palette = colors)\n",
        "plt.title('CTR Distribution by Campaign')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VP5-npKQfYkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Violin chart of CTR"
      ],
      "metadata": {
        "id": "jNGDKBBFIH9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = sns.color_palette(['#7CC674', '#F0AB00'])\n",
        "\n",
        "sns.violinplot(x='Campaign Name', y='CTR_Normalized', data=combined_data_df,\n",
        "            hue='Campaign Name', dodge=False, palette = colors)\n",
        "plt.title('CTR Distribution by Campaign')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jig-7QuSHtwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CR, Conversion rate"
      ],
      "metadata": {
        "id": "dZ9MEuOMIkYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bar chart of CR"
      ],
      "metadata": {
        "id": "cYVtJhpWIrKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = sns.color_palette(['#06C', '#F4B678'])\n",
        "\n",
        "sns.barplot(data=calculations_df, x='Campaign Name',\n",
        "                    y='CR_Percent', hue='Campaign Name', palette = colors, dodge=False)\n",
        "plt.title('Average Metrics of CR')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MzmBLhflI_3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Box chart of CR"
      ],
      "metadata": {
        "id": "9DMWP0pz4pYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = sns.color_palette(['#73C5C5', '#A30000'])\n",
        "\n",
        "sns.boxplot(x='Campaign Name', y='CR_Normalized', data=combined_data_df,\n",
        "            hue='Campaign Name', palette = colors, dodge=False)\n",
        "plt.title('CR Distribution by Campaign')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rz2YDMX7Jovb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Violin chart of CR"
      ],
      "metadata": {
        "id": "oq52ycnU4plH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = sns.color_palette(['#7CC674', '#F0AB00'])\n",
        "\n",
        "sns.violinplot(x='Campaign Name', y='CR_Normalized', data=combined_data_df,\n",
        "            hue='Campaign Name', palette = colors, dodge=False)\n",
        "plt.title('CR Distribution by Campaign')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "48chBuNwJx2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis and Conclusions"
      ],
      "metadata": {
        "id": "TMgKSwHyKQ2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CTR (Click-Through Rate):**\n",
        "\n",
        "Visual Observation: The histogram for CTR shows a higher mean for the Test Campaign compared to the Control Campaign.\n",
        "The KDE line for the Test Campaign is consistently above that of the Control Campaign.\n",
        "There are more outliers on the right for the Test Campaign than for the Control Campaign.\n",
        "Conclusion: The Test Campaign has a higher CTR, indicating better engagement.\n",
        "\n",
        "\n",
        "\n",
        "**CR (Conversion Rate):**\n",
        "\n",
        "Visual Observation: The histogram for CR shows similar means for both Control and Test Campaigns, with the Test Campaign\n",
        "having a slightly lower mean. The KDE lines overlap considerably, indicating similar distributions.\n",
        "Conclusion: There is no significant difference in CR between the Control and Test Campaigns."
      ],
      "metadata": {
        "id": "sQFkw_szNsIu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The End ðŸ›‘"
      ],
      "metadata": {
        "id": "xFsznQ6U4pyF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Wux5LLh9Nshb"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}