{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anumit-web/ML-Analytics-Portfolio-2024/blob/main/8.%20Market%20Basket%20Analysis/Market%20Basket%20Analysis%20-%202.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Artificial Intelligence\n",
        "# Machine Learning\n",
        "# Portfolio Project\n",
        "# #8\n",
        "# Market Basket Analysis\n",
        "# Goal = Conduct market basket analysis to identify product associations and customer buying patterns.\n",
        "\n",
        "# unsupervised learning\n",
        "\n",
        "# find what item a customer is most likely to buy based on information about customer purchase history data\n",
        "\n",
        "# Apriori algorithm\n",
        "## a machine learning algorithm used to find frequent itemsets and association rules in data\n",
        "\n",
        "# Identify frequent items\n",
        "## identifying the most frequent individual items in the data\n",
        "\n",
        "# Association rules\n",
        "## a rule might say that if items A and B are in a transaction, then item C is likely to be included as well\n",
        "\n",
        "## The Apriori algorithm uses the insight that adding items to a frequently purchased group can only make it less frequent.\n",
        "\n",
        "## The algorithm requires two important parameters: minimum support and minimum confidence\n",
        "\n",
        "# support\n",
        "## Support basically refers to the number of times the chosen item/s appears in the database\n",
        "\n",
        "# Confidence\n",
        "## Confidence refers to the frequency of A and B being together, given the number of times A has occurred.\n",
        "\n",
        "# Lift\n",
        "## the likelihood of the itemset B being purchased when item A is purchased while taking into account the support of B\n",
        "\n",
        "# Market Basket Analysis\n",
        "## customers who buy a certain item (or group of items) are more likely to buy another specific item (or group of items)\n",
        "\n",
        "## The relations hence can be used to increase profitability through cross-selling, recommendations, promotions, or even the placement of items on a menu or in a store.\n",
        "\n",
        "\n",
        "# https://en.wikipedia.org/wiki/Apriori_algorithm\n",
        "\n",
        "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n"
      ],
      "metadata": {
        "id": "LAElxz7e6xiT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Branding statement"
      ],
      "metadata": {
        "id": "-AqinKkKYcIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://i.ibb.co/zZswY34/Pink-hands-network-2.png"
      ],
      "metadata": {
        "id": "et0ThJcPYiXb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('https://i.ibb.co/zZswY34/Pink-hands-network-2.png')"
      ],
      "metadata": {
        "id": "eejritJ1YnWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -"
      ],
      "metadata": {
        "id": "GRLJj5WkZYii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA, Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "P2GTILYG7D1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import libraries"
      ],
      "metadata": {
        "id": "vSS7v0tO2Nc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Hello, Market Basket Analysis')"
      ],
      "metadata": {
        "id": "bijVEivnAsug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "vsLbE4-Z-pdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input data"
      ],
      "metadata": {
        "id": "zlPRSWa00y-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://github.com/anumit-web/ML-Analytics-Portfolio-2024/blob/main/8.%20Market%20Basket%20Analysis/dataset/Assignment-1_Data.csv.zip?raw=true"
      ],
      "metadata": {
        "id": "heE-K4n2fuK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://github.com/anumit-web/ML-Analytics-Portfolio-2024/blob/main/8.%20Market%20Basket%20Analysis/dataset/Assignment-1_Data.csv.zip"
      ],
      "metadata": {
        "id": "LjUVpWvf_BMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raise SystemExit(\"Stop right there!\")"
      ],
      "metadata": {
        "id": "qIqKa1aXusyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df = pd.read_csv(\"https://raw.githubusercontent.com/anumit-web/ML-Analytics-Portfolio-2024/refs/heads/main/7.%20Financial%20Analysis%20and%20Modeling/datasets/NFLX.csv\")"
      ],
      "metadata": {
        "id": "GqVUsHF_EUrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_rows = input_data_df.shape[0]\n",
        "number_of_columns = input_data_df.shape[1]\n",
        "print(\"Numner of rows = \", number_of_rows)\n",
        "print(\"Number of columns = \", number_of_columns)"
      ],
      "metadata": {
        "id": "J5htDQ-5hTmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "o7enKsiz_UEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df.tail()"
      ],
      "metadata": {
        "id": "SGHOpPwkXjte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df.info()"
      ],
      "metadata": {
        "id": "S_h0_YgEXsVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df.describe()\n"
      ],
      "metadata": {
        "id": "N5WFB738XyUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "print column names"
      ],
      "metadata": {
        "id": "GUlKmkJKaoSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_data_df.columns)"
      ],
      "metadata": {
        "id": "L5hw6CkxZTo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all Column Header Labels as List\n",
        "for column_headers in  input_data_df.columns:\n",
        "    print(column_headers)"
      ],
      "metadata": {
        "id": "SNohuK30aZ-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## find list of all columns which have null values\n",
        "using SKIMPY"
      ],
      "metadata": {
        "id": "-6YgPJxE3ALE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the count of null values in each column\n",
        "null_counts = input_data_df.isnull().sum()\n",
        "print('Priniting count of null values = ')\n",
        "print(null_counts)"
      ],
      "metadata": {
        "id": "4TQRUjgl9NSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import skimpy\n",
        "except:\n",
        "  !pip install skimpy\n",
        "  import skimpy"
      ],
      "metadata": {
        "id": "4YTP4QMQ-n0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install skimpy"
      ],
      "metadata": {
        "id": "JXCuQMzKcRv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimpy import skim"
      ],
      "metadata": {
        "id": "ihugGf-bcd-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skim(input_data_df)"
      ],
      "metadata": {
        "id": "Ol4qOryGckPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## find unique values by column names"
      ],
      "metadata": {
        "id": "Eh836kWO3jwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the number of unique values in both 'Name' and 'Age' columns\n",
        "unique_values = input_data_df.nunique()\n",
        "print(unique_values)"
      ],
      "metadata": {
        "id": "-uIq1pUW-fG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import summarytools\n",
        "except:\n",
        "  !pip install summarytools\n",
        "  import summarytools"
      ],
      "metadata": {
        "id": "WBNzRoXv_Q6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install summarytools"
      ],
      "metadata": {
        "id": "r29v3j-ndm_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from summarytools import dfSummary"
      ],
      "metadata": {
        "id": "QH1rhk3zdxt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfSummary(input_data_df)"
      ],
      "metadata": {
        "id": "O4BP8AQvd1hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "na0uFDyjW7gl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "convert date column to date data tupe"
      ],
      "metadata": {
        "id": "BrF3DEDa5VVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print\n",
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "kw6A08RozjR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df[\"Date\"]=pd.to_datetime(input_data_df[\"Date\"])"
      ],
      "metadata": {
        "id": "ttXGaXayzE9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "UWJOx1JU0c13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df.dtypes"
      ],
      "metadata": {
        "id": "PUqYmMo_1SCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "change index to date tyoe and date column"
      ],
      "metadata": {
        "id": "vUrAkzph5g5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df.index = input_data_df['Date']"
      ],
      "metadata": {
        "id": "fQVOfpEf4Rrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "h4SeF6Qn4fQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "do NOT drop date column because we need it for model training for linear and random forest algorithms"
      ],
      "metadata": {
        "id": "VJotgyyaxcHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input_data_df = input_data_df.drop('Date', axis=1)\n",
        "# where 1 is the axis number (0 for rows and 1 for columns.)"
      ],
      "metadata": {
        "id": "ddufAvqP6FoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "-oPPZotd6QvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d2ciBozmx3La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization ðŸ“ŠðŸ“ˆðŸ“‰"
      ],
      "metadata": {
        "id": "ZxkH60cC3ecY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## create histogram"
      ],
      "metadata": {
        "id": "YTGfPAm67Con"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df.hist(bins=50, figsize=(25, 20))"
      ],
      "metadata": {
        "id": "ajqfAYOs7F4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plot time series graphs for each column"
      ],
      "metadata": {
        "id": "dXrtj3uguymQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df.plot(subplots=True, layout=(5,2), figsize=(18, 20))\n",
        "\n",
        "# ( rows, coluumns)"
      ],
      "metadata": {
        "id": "iWVZYLbsuqqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Calculations"
      ],
      "metadata": {
        "id": "jd0vqbaVZiEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## strategy\n",
        "1. Select one of the columns to test and train = high, low, volumne\n",
        "2. Select input data into test and train\n",
        "3. Run your models\n",
        "    a. Linear regression\n",
        "    b. Random Forest\n",
        "4. Stop Words\n",
        "5. Stemming\n",
        "6. Lemmatization\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vfrS4mypZi2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization"
      ],
      "metadata": {
        "id": "R-oLO-_9BfZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression"
      ],
      "metadata": {
        "id": "y3uTPhn_qw8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "date vs volume\n",
        "\n",
        "predict values of volume\n",
        "\n",
        "Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables\n",
        "\n",
        "independent variable = date\n",
        "dependent variable = volume"
      ],
      "metadata": {
        "id": "ET4oryzXu9oA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()"
      ],
      "metadata": {
        "id": "jiWGFvkUuJDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "zpBpqNYbCFlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = input_data_df.copy()\n",
        "y = input_data_df['Close']"
      ],
      "metadata": {
        "id": "Y8mXJDjR2bcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(x)"
      ],
      "metadata": {
        "id": "oitW4reGkP-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(y)"
      ],
      "metadata": {
        "id": "ewXGUjaOkZeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x2 = x.to_frame()\n",
        "x2 = x\n",
        "\n",
        "# print\n",
        "x2"
      ],
      "metadata": {
        "id": "1obsA_-TmSjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y2 = y.to_frame()\n",
        "y2 = y\n",
        "\n",
        "#print\n",
        "y2"
      ],
      "metadata": {
        "id": "BDcOvTCLmap5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x3 = x2.reset_index(drop=True)\n",
        "x3 = x2\n",
        "# drop column 'B'\n",
        "x3 = x3.drop('Date', axis=1)\n",
        "\n",
        "# print\n",
        "x3"
      ],
      "metadata": {
        "id": "M1HP_UCdnh4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y3 =  y2.reset_index(drop=True)\n",
        "y3 = y2\n",
        "\n",
        "# print\n",
        "y3"
      ],
      "metadata": {
        "id": "bZ7wbpUNoUPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Data type = ( x3 = )',type(x3),  'y3 =', type(y3))"
      ],
      "metadata": {
        "id": "UmgpN3MdMvrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(x3, y3)\n",
        "# model.fit(x3.values.reshape(-1, 1), y3.values.reshape(-1, 1))\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "# r2_score = model.score(x3.values.astype(float).reshape(-1, 1), y3.values.reshape(-1, 1))\n",
        "r2_score = model.score(x3, y3)\n",
        "print(f\"R-squared value: {r2_score}\")"
      ],
      "metadata": {
        "id": "qe0jWNDW3w4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "ZXmfggPye058"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_rand = RandomForestRegressor(n_estimators=200, random_state = 42)"
      ],
      "metadata": {
        "id": "HD2AnkkDe4PH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_rand.fit(x, y)"
      ],
      "metadata": {
        "id": "9CAUa4Ppe7U0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score-rf = model.score(x3, y3)\n",
        "print(f\"R-squared value: {r2_scor_rf}\")"
      ],
      "metadata": {
        "id": "5-NkVFO_gfkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The R-squared value measures how well the linear regression model fits the data, ranging from 0 to 1, where 1 indicates a perfect fit."
      ],
      "metadata": {
        "id": "KXm8cnJ333h_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_location = input_data_df.columns.get_loc('text')\n",
        "\n",
        "# Create a new column 'Country'\n",
        "input_data_df['text_processed'] = \"\"\n",
        "\n",
        "# Insert the 'Country' column after the 'Name' column\n",
        "input_data_df.insert(text_location + 1, 'text_processed', input_data_df.pop('text_processed'))\n",
        "\n",
        "text_processed_location = input_data_df.columns.get_loc('text_processed')\n",
        "\n",
        "# Create a new column 'Country'\n",
        "input_data_df['text_processed_2'] = \"\"\n",
        "\n",
        "# Insert the 'Country' column after the 'Name' column\n",
        "input_data_df.insert(text_processed_location + 1, 'text_processed_2', input_data_df.pop('text_processed_2'))\n",
        "\n",
        "text_processed_location_2 = input_data_df.columns.get_loc('text_processed_2')\n",
        "\n",
        "# Create a new column 'Country'\n",
        "input_data_df['text_processed_3'] = \"\"\n",
        "\n",
        "# Insert the 'Country' column after the 'Name' column\n",
        "input_data_df.insert(text_processed_location_2 + 1, 'text_processed_3', input_data_df.pop('text_processed_3'))\n",
        "\n",
        "\n",
        "# print\n",
        "\n",
        "input_data_df.head()\n",
        "\n",
        "# print\n",
        "\n",
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "C0ar_eP0DVEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zpFTrK1WPvXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Lower case string"
      ],
      "metadata": {
        "id": "cAZ5LcyMgXmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df['text_processed'] = input_data_df['text'].str.lower()\n",
        "\n",
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "BB8jsoD0IRlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. tokenize sentenses"
      ],
      "metadata": {
        "id": "z4rbIpfrhYDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "metadata": {
        "id": "d7HlNSriF-tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Tokenize the 'text' column and put the result in a new column 'tokens'\n",
        "input_data_df['text_processed'] = input_data_df['text_processed'].apply(word_tokenize)\n",
        "\n",
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "lFsttLD1GSzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## punctuation removal"
      ],
      "metadata": {
        "id": "AZAbNSOthSCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_data_df['text_processed_2'] = input_data_df['text_processed'].copy()\n",
        "\n",
        "input_data_df.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "lgRbG_EGDWAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df.loc[:, 'text_processed_3'] = input_data_df.loc[:, 'text_processed_2']\n",
        "\n",
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "bW9U0R5GlFRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "# input_data_df['text_processed_2'] = input_data_df['text_processed'].copy()\n",
        "\n",
        "def remove_punctuation(tokens):\n",
        "\n",
        "  tokens2 = []\n",
        "  for word in tokens:\n",
        "    #if (word in string.punctuation):\n",
        "      #tokens.remove(word)\n",
        "    if(word not in string.punctuation):\n",
        "      tokens2.append(word)\n",
        "\n",
        "  #return tokens\n",
        "  return tokens2\n",
        "  # return \"\"\n",
        "\n",
        "# input_data_df['text_processed_2'] = input_data_df['text_processed']\n",
        "input_data_df['text_processed_3'] = input_data_df['text_processed_3'].apply(remove_punctuation)\n",
        "\n",
        "input_data_df.head(5)\n",
        "\n",
        "# input_data_df['text', 'text_processed'].head()"
      ],
      "metadata": {
        "id": "AZjskqAfJFrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## stop words removal"
      ],
      "metadata": {
        "id": "hD4WKtjmuL1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "EFr3RpDpufj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def remove_stop_words(tokens):\n",
        "\n",
        "  tokens2 = []\n",
        "  for word in tokens:\n",
        "    #if (word in stopwords.words('english')):\n",
        "       #tokens.remove(word)\n",
        "    if ( word not in stopwords.words('english')):\n",
        "         tokens2.append(word)\n",
        "\n",
        "  #return tokens\n",
        "  return tokens2\n",
        "\n",
        "input_data_df['text_processed_3'] = input_data_df['text_processed_3'].apply(remove_stop_words)\n",
        "\n",
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "sDxqwB_quicS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. stemming"
      ],
      "metadata": {
        "id": "80M2B1Kjxu-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "metadata": {
        "id": "6SqPmHx6x05n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "porter_stemmer = PorterStemmer()\n",
        "snowball_stemmer = SnowballStemmer(\"english\") # use this algorithm as it is new version of porter\n",
        "\n",
        "def stemwords_in_sentence(tokens):\n",
        "  stemmed_words = []\n",
        "  for word in tokens:\n",
        "      stemmed_word = snowball_stemmer.stem(word)\n",
        "      stemmed_words.append(stemmed_word)\n",
        "\n",
        "\n",
        "  return stemmed_words\n",
        "\n",
        "input_data_df['text_processed_3'] = input_data_df['text_processed_3'].apply(stemwords_in_sentence)\n",
        "\n",
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "JB5TqOeozOHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. lemming"
      ],
      "metadata": {
        "id": "83Ik5U-1-e1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "expVZgIU-ko9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_in_sentence(tokens):\n",
        "  lemmatized_words = []\n",
        "  for word in tokens:\n",
        "      lemmatized_word =   lemmatizer.lemmatize(word)\n",
        "      lemmatized_words.append(lemmatized_word)\n",
        "\n",
        "\n",
        "  return lemmatized_words\n",
        "\n",
        "input_data_df['text_processed_3'] = input_data_df['text_processed_3'].apply(lemmatize_in_sentence)\n",
        "\n",
        "input_data_df.head()\n"
      ],
      "metadata": {
        "id": "7HVCYeMO-oDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Join tokens into string"
      ],
      "metadata": {
        "id": "7bMDT1HzWtQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input_data_df['text_processed_3'] ="
      ],
      "metadata": {
        "id": "MQTND5yRXpU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_processed_location_3 = input_data_df.columns.get_loc('text_processed_3')\n",
        "\n",
        "# Create a new column 'Country'\n",
        "input_data_df['text_processed_4'] = \"\"\n",
        "\n",
        "# Insert the 'Country' column after the 'Name' column\n",
        "input_data_df.insert(text_processed_location_3 + 1, 'text_processed_4', input_data_df.pop('text_processed_4'))\n",
        "\n"
      ],
      "metadata": {
        "id": "z1Hq-WVJZObq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df['text_processed_4'] = input_data_df['text_processed_3'].apply(lambda token: ' '.join(token))"
      ],
      "metadata": {
        "id": "5jLgZZ1XAdXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "xx28FDUpYfSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change column names"
      ],
      "metadata": {
        "id": "Tvc1t_iNZjXG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fill mean average values in rows and columns"
      ],
      "metadata": {
        "id": "dlI7AVmNOUJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process combined data from control group and test group"
      ],
      "metadata": {
        "id": "iVyBC2XdQiuR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Calculations"
      ],
      "metadata": {
        "id": "UcZlGRiCMT1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find sentiment of tweets and posts"
      ],
      "metadata": {
        "id": "rUjHz0QUTLqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VADER (Valence Aware Dictionary and sEntiment Reasoner)"
      ],
      "metadata": {
        "id": "kfVKWCcVT5mN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "negative, neutral, and positive scores\n",
        "\n",
        "compound score can range from -1 to 1."
      ],
      "metadata": {
        "id": "GRwSSjKaaKXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "daLN9xeyTKpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sia = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "71qirqBaV1EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sia.polarity_scores(\"Wow, NLTK is really powerful!\")"
      ],
      "metadata": {
        "id": "9gqJynpHUNky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sia.polarity_scores(\"I had a bad experience at the geocery store!\")"
      ],
      "metadata": {
        "id": "l--_EqsNaIdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sia.polarity_scores(\"I am going to office\")"
      ],
      "metadata": {
        "id": "iOrh718Ucbd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create get_sentiment function\n",
        "\n",
        "def get_sentiment(text):\n",
        "\n",
        "    scores = sia.polarity_scores(text)\n",
        "\n",
        "    if scores['compound'] > 0 :\n",
        "        new_sentiment = 1\n",
        "    if scores['compound'] == 0 :\n",
        "        new_sentiment = 0\n",
        "    if scores['compound'] < 0 :\n",
        "        new_sentiment = -1\n",
        "\n",
        "    return new_sentiment\n",
        "\n",
        "\n",
        "# apply get_sentiment function\n",
        "\n",
        "input_data_df['calculated_sentiment'] = input_data_df['text_processed_4'].apply(get_sentiment)\n",
        "\n",
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "Fs7POSe-aaR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by the 'Name' column and count the number of rows in each group\n",
        "result =  input_data_df.groupby('calculated_sentiment').size()\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "EsYPlXBohCT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_location = input_data_df.columns.get_loc('sentiment')\n",
        "\n",
        "# Create a new column 'Country'\n",
        "input_data_df['sentiment_to_number'] = 9999999\n",
        "\n",
        "# Insert the 'Country' column after the 'Name' column\n",
        "input_data_df.insert(sentiment_location + 1, 'sentiment_to_number', input_data_df.pop('sentiment_to_number'))\n",
        "\n",
        "input_data_df.head()"
      ],
      "metadata": {
        "id": "BiyR_mFpi40t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_sentiment_to_number(sentiment):\n",
        "\n",
        "  sentiment_number = 66666666\n",
        "\n",
        "  if(sentiment == 'positive'):\n",
        "    sentiment_number = 1\n",
        "  if(sentiment == 'neutral'):\n",
        "    sentiment_number = 0\n",
        "  if(sentiment == 'negative'):\n",
        "     sentiment_number = -1\n",
        "\n",
        "  return sentiment_number\n",
        "  # return \"\"\n",
        "\n",
        "# input_data_df['text_processed_2'] = input_data_df['text_processed']\n",
        "input_data_df['sentiment_to_number'] = input_data_df['sentiment'].apply(convert_sentiment_to_number)\n",
        "\n",
        "input_data_df.head(5)"
      ],
      "metadata": {
        "id": "6d1mY-5ojhPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion marrix"
      ],
      "metadata": {
        "id": "8WS-2ZEvZj1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "40pqd5-M4xgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KMuQ-fgyBSF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix = confusion_matrix(input_data_df['sentiment_to_number'],\n",
        "                             input_data_df['calculated_sentiment'])\n",
        "print(cf_matrix)"
      ],
      "metadata": {
        "id": "izcyNsS35J-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(input_data_df['sentiment_to_number'], input_data_df['calculated_sentiment']))"
      ],
      "metadata": {
        "id": "9Hl5MmUx_WAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "s3G5KLkMBP5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(cf_matrix, annot=True)"
      ],
      "metadata": {
        "id": "16WCa1nH-SrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True,\n",
        "            fmt='.2%', cmap='Blues')"
      ],
      "metadata": {
        "id": "DEcl4CUZ-Xqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
        "group_counts = [â€œ{0:0.0f}â€.format(value) for value in\n",
        "                cf_matrix.flatten()]\n",
        "group_percentages = [â€œ{0:.2%}â€.format(value) for value in\n",
        "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
        "labels = [fâ€{v1}\\n{v2}\\n{v3}â€ for v1, v2, v3 in\n",
        "          zip(group_names,group_counts,group_percentages)]\n",
        "labels = np.asarray(labels).reshape(2,2)\n",
        "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')"
      ],
      "metadata": {
        "id": "SPJMEtRJ-6jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conversion Rate\n",
        "\n",
        "Conversion Rate = (Number of Conversions / Number of Visitors) x 100"
      ],
      "metadata": {
        "id": "PyRat1vNZkWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "add new columns\n",
        "normalized = value between 0 and 1\n",
        "percent = value between 0 and 100"
      ],
      "metadata": {
        "id": "TwTvrOgmdVlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data_df['CTR_Normalized'] = 0\n",
        "combined_data_df['CTR_Percent'] = 0\n",
        "combined_data_df['CR_Normalized'] = 0\n",
        "combined_data_df['CR_Percent'] = 0\n",
        "\n",
        "#print\n",
        "combined_data_df.head()"
      ],
      "metadata": {
        "id": "5tnj2RQpdZNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data_df['CTR_Normalized'] = (combined_data_df['Clicks'] /\n",
        "                      combined_data_df['Impressions'])\n",
        "\n",
        "combined_data_df['CTR_Percent'] = (combined_data_df['Clicks'] /\n",
        "                      combined_data_df['Impressions']) * 100\n",
        "\n",
        "# print\n",
        "combined_data_df.head()"
      ],
      "metadata": {
        "id": "FaiaLuaGfKdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data_df['CR_Normalized'] = (combined_data_df['Purchases'] /\n",
        "                      combined_data_df['Clicks'])\n",
        "\n",
        "combined_data_df['CR_Percent'] = (combined_data_df['Purchases'] /\n",
        "                      combined_data_df['Clicks']) * 100\n",
        "\n",
        "\n",
        "#print\n",
        "combined_data_df.head()"
      ],
      "metadata": {
        "id": "vFMAAvgvf6jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CTR\n",
        "\n",
        "temp_df1 = combined_data_df.groupby('Campaign Name')['CTR_Normalized'].mean()\n"
      ],
      "metadata": {
        "id": "MfPy_ezyztOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df2 = combined_data_df.groupby('Campaign Name')['CR_Normalized'].mean()"
      ],
      "metadata": {
        "id": "r9SIDO1X0BsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df3 = combined_data_df.groupby('Campaign Name')['CTR_Percent'].mean()"
      ],
      "metadata": {
        "id": "59hifgR91eou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df4 = combined_data_df.groupby('Campaign Name')['CR_Percent'].mean()"
      ],
      "metadata": {
        "id": "dGOKDMdA1oYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df5 = pd.merge(temp_df1, temp_df2, on='Campaign Name')\n",
        "\n",
        "#print\n",
        "temp_df5"
      ],
      "metadata": {
        "id": "D8dsC1Se1CkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df6 = pd.merge(temp_df3, temp_df4, on='Campaign Name')"
      ],
      "metadata": {
        "id": "K0bSUg1V2Epg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df7 = pd.merge(temp_df5, temp_df6, on='Campaign Name')\n",
        "\n",
        "# print\n",
        "temp_df7"
      ],
      "metadata": {
        "id": "ftelQiYj2LVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculations_df = temp_df7\n",
        "\n",
        "# print\n",
        "temp_df7"
      ],
      "metadata": {
        "id": "vGJ3edLt2sno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "seperator"
      ],
      "metadata": {
        "id": "gnTBZzuD3KbA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "seperator"
      ],
      "metadata": {
        "id": "Q3ZC4rWl3ORh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "bF-P0sW24ipO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CTR , Click through rate"
      ],
      "metadata": {
        "id": "dOJrb6dj5Iun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bar chart of CTR"
      ],
      "metadata": {
        "id": "G0kluhEVZk7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = sns.color_palette(['#06C', '#F4B678'])\n",
        "\n",
        "sns.barplot(data=calculations_df, x='Campaign Name',\n",
        "                    y='CTR_Percent', hue='Campaign Name', palette = colors, dodge=False)\n",
        "plt.title('Average Metrics of CTR')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0hxBXqqw5Y36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Box chart of CTR"
      ],
      "metadata": {
        "id": "iRPnlOoO4pJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = sns.color_palette(['#73C5C5', '#A30000'])\n",
        "\n",
        "sns.boxplot(x='Campaign Name', y='CTR_Normalized', data=combined_data_df,\n",
        "            hue='Campaign Name', dodge=False, palette = colors)\n",
        "plt.title('CTR Distribution by Campaign')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VP5-npKQfYkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Violin chart of CTR"
      ],
      "metadata": {
        "id": "jNGDKBBFIH9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = sns.color_palette(['#7CC674', '#F0AB00'])\n",
        "\n",
        "sns.violinplot(x='Campaign Name', y='CTR_Normalized', data=combined_data_df,\n",
        "            hue='Campaign Name', dodge=False, palette = colors)\n",
        "plt.title('CTR Distribution by Campaign')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jig-7QuSHtwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CR, Conversion rate"
      ],
      "metadata": {
        "id": "dZ9MEuOMIkYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bar chart of CR"
      ],
      "metadata": {
        "id": "cYVtJhpWIrKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = sns.color_palette(['#06C', '#F4B678'])\n",
        "\n",
        "sns.barplot(data=calculations_df, x='Campaign Name',\n",
        "                    y='CR_Percent', hue='Campaign Name', palette = colors, dodge=False)\n",
        "plt.title('Average Metrics of CR')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MzmBLhflI_3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Box chart of CR"
      ],
      "metadata": {
        "id": "9DMWP0pz4pYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = sns.color_palette(['#73C5C5', '#A30000'])\n",
        "\n",
        "sns.boxplot(x='Campaign Name', y='CR_Normalized', data=combined_data_df,\n",
        "            hue='Campaign Name', palette = colors, dodge=False)\n",
        "plt.title('CR Distribution by Campaign')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rz2YDMX7Jovb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Violin chart of CR"
      ],
      "metadata": {
        "id": "oq52ycnU4plH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = sns.color_palette(['#7CC674', '#F0AB00'])\n",
        "\n",
        "sns.violinplot(x='Campaign Name', y='CR_Normalized', data=combined_data_df,\n",
        "            hue='Campaign Name', palette = colors, dodge=False)\n",
        "plt.title('CR Distribution by Campaign')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "48chBuNwJx2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis and Conclusions"
      ],
      "metadata": {
        "id": "TMgKSwHyKQ2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CTR (Click-Through Rate):**\n",
        "\n",
        "Visual Observation: The histogram for CTR shows a higher mean for the Test Campaign compared to the Control Campaign.\n",
        "The KDE line for the Test Campaign is consistently above that of the Control Campaign.\n",
        "There are more outliers on the right for the Test Campaign than for the Control Campaign.\n",
        "Conclusion: The Test Campaign has a higher CTR, indicating better engagement.\n",
        "\n",
        "\n",
        "\n",
        "**CR (Conversion Rate):**\n",
        "\n",
        "Visual Observation: The histogram for CR shows similar means for both Control and Test Campaigns, with the Test Campaign\n",
        "having a slightly lower mean. The KDE lines overlap considerably, indicating similar distributions.\n",
        "Conclusion: There is no significant difference in CR between the Control and Test Campaigns."
      ],
      "metadata": {
        "id": "sQFkw_szNsIu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The End ðŸ›‘"
      ],
      "metadata": {
        "id": "xFsznQ6U4pyF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Wux5LLh9Nshb"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}